{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vader_and_load_yelp_data_from_s3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkZXrKuqgWM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "2a04dba3-558f-4470-ba11-1c790a5a3885"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "!pip install fastparquet\n",
        "from fastparquet import ParquetFile\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "#imports to get our parquet files aand dask files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastparquet in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.0.4)\n",
            "Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.13.0)\n",
            "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.48.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (47.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBuYPNNa6V53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "943ba88b-5e6c-4cdc-8005-8eeda54fb548"
      },
      "source": [
        "#load dask in as read_parquet\n",
        "reviews = dd.read_parquet('https://tally-ai-dspt3.s3.amazonaws.com/yelp-restaurants/reviews.parquet.gzip')\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>reviews_stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ipufYjKx5saLVuDR6f6o0w</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-21 02:03:08</td>\n",
              "      <td>Was there with a girlfriend at lunch time toda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VNOhF-xUYguSjA01yx5nwA</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-08-20 17:46:40</td>\n",
              "      <td>I thought my meal was OK. I ordered an omelett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PMXYXphbbkx2TM80AtIpQQ</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-12-10 17:53:39</td>\n",
              "      <td>It's just a breakfast not too fancy. Weak coff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7hxilsquX34WXHYc80qLkw</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-09-02 18:54:37</td>\n",
              "      <td>Shoule be zero stars! So, we have been here a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Xnf39DsDWqiv1wulL2NK9g</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-30 05:33:08</td>\n",
              "      <td>I LOVE this place!!! I'm so happy they opened ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id             business_id  reviews_stars  \\\n",
              "index                                                                  \n",
              "0      ipufYjKx5saLVuDR6f6o0w  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "1      VNOhF-xUYguSjA01yx5nwA  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "2      PMXYXphbbkx2TM80AtIpQQ  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "3      7hxilsquX34WXHYc80qLkw  S9RoY_Smsh0a2JPo90bkdg              1   \n",
              "4      Xnf39DsDWqiv1wulL2NK9g  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "\n",
              "                     date                                               text  \n",
              "index                                                                         \n",
              "0     2017-08-21 02:03:08  Was there with a girlfriend at lunch time toda...  \n",
              "1     2017-08-20 17:46:40  I thought my meal was OK. I ordered an omelett...  \n",
              "2     2015-12-10 17:53:39  It's just a breakfast not too fancy. Weak coff...  \n",
              "3     2017-09-02 18:54:37  Shoule be zero stars! So, we have been here a ...  \n",
              "4     2017-04-30 05:33:08  I LOVE this place!!! I'm so happy they opened ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWnexhtG6V21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "757e0236-5e52-44d4-f6db-eb717b5c79d9"
      },
      "source": [
        "#load dask in as read_parquet\n",
        "business = dd.read_csv('https://tally-ai-dspt3.s3.amazonaws.com/yelp-restaurants/business.csv', blocksize=None)\n",
        "business.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>address</th>\n",
              "      <th>attributes</th>\n",
              "      <th>business_id</th>\n",
              "      <th>categories</th>\n",
              "      <th>city</th>\n",
              "      <th>hours</th>\n",
              "      <th>is_open</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>review_count</th>\n",
              "      <th>state</th>\n",
              "      <th>business_stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>404 E Green St</td>\n",
              "      <td>{'RestaurantsAttire': \"u'casual'\", 'Restaurant...</td>\n",
              "      <td>pQeaRpvuhoEqudo3uymHIQ</td>\n",
              "      <td>Ethnic Food, Food Trucks, Specialty Food, Impo...</td>\n",
              "      <td>Champaign</td>\n",
              "      <td>{'Monday': '11:30-14:30', 'Tuesday': '11:30-14...</td>\n",
              "      <td>1</td>\n",
              "      <td>40.110446</td>\n",
              "      <td>-88.233073</td>\n",
              "      <td>The Empanadas House</td>\n",
              "      <td>61820</td>\n",
              "      <td>5</td>\n",
              "      <td>IL</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>4508 E Independence Blvd</td>\n",
              "      <td>{'RestaurantsGoodForGroups': 'True', 'OutdoorS...</td>\n",
              "      <td>CsLQLiRoafpJPJSkNX2h5Q</td>\n",
              "      <td>Food, Restaurants, Grocery, Middle Eastern</td>\n",
              "      <td>Charlotte</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>35.194894</td>\n",
              "      <td>-80.767442</td>\n",
              "      <td>Middle East Deli</td>\n",
              "      <td>28205</td>\n",
              "      <td>5</td>\n",
              "      <td>NC</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>15480 Bayview Avenue, unit D0110</td>\n",
              "      <td>{'RestaurantsTableService': 'False', 'Restaura...</td>\n",
              "      <td>eBEfgOPG7pvFhb2wcG9I7w</td>\n",
              "      <td>Restaurants, Cheesesteaks, Poutineries</td>\n",
              "      <td>Aurora</td>\n",
              "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
              "      <td>1</td>\n",
              "      <td>44.010962</td>\n",
              "      <td>-79.448677</td>\n",
              "      <td>Philthy Phillys</td>\n",
              "      <td>L4G 7J1</td>\n",
              "      <td>4</td>\n",
              "      <td>ON</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>300 John Street</td>\n",
              "      <td>{'GoodForKids': 'True', 'RestaurantsTakeOut': ...</td>\n",
              "      <td>lu7vtrp_bE9PnxWfA8g4Pg</td>\n",
              "      <td>Japanese, Fast Food, Food Court, Restaurants</td>\n",
              "      <td>Thornhill</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>43.820492</td>\n",
              "      <td>-79.398466</td>\n",
              "      <td>Banzai Sushi</td>\n",
              "      <td>L3T 5W4</td>\n",
              "      <td>7</td>\n",
              "      <td>ON</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>13071 Yonge Street</td>\n",
              "      <td>{'Ambience': \"{'touristy': False, 'hipster': F...</td>\n",
              "      <td>9sRGfSVEfLhN_km60YruTA</td>\n",
              "      <td>Persian/Iranian, Turkish, Middle Eastern, Rest...</td>\n",
              "      <td>Richmond Hill</td>\n",
              "      <td>{'Tuesday': '12:0-21:0', 'Wednesday': '12:0-21...</td>\n",
              "      <td>1</td>\n",
              "      <td>43.947011</td>\n",
              "      <td>-79.454862</td>\n",
              "      <td>Apadana Restaurant</td>\n",
              "      <td>L4E 1A5</td>\n",
              "      <td>3</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                           address  \\\n",
              "0           8                    404 E Green St   \n",
              "1          20          4508 E Independence Blvd   \n",
              "2          24  15480 Bayview Avenue, unit D0110   \n",
              "3          25                   300 John Street   \n",
              "4          30                13071 Yonge Street   \n",
              "\n",
              "                                          attributes             business_id  \\\n",
              "0  {'RestaurantsAttire': \"u'casual'\", 'Restaurant...  pQeaRpvuhoEqudo3uymHIQ   \n",
              "1  {'RestaurantsGoodForGroups': 'True', 'OutdoorS...  CsLQLiRoafpJPJSkNX2h5Q   \n",
              "2  {'RestaurantsTableService': 'False', 'Restaura...  eBEfgOPG7pvFhb2wcG9I7w   \n",
              "3  {'GoodForKids': 'True', 'RestaurantsTakeOut': ...  lu7vtrp_bE9PnxWfA8g4Pg   \n",
              "4  {'Ambience': \"{'touristy': False, 'hipster': F...  9sRGfSVEfLhN_km60YruTA   \n",
              "\n",
              "                                          categories           city  \\\n",
              "0  Ethnic Food, Food Trucks, Specialty Food, Impo...      Champaign   \n",
              "1         Food, Restaurants, Grocery, Middle Eastern      Charlotte   \n",
              "2             Restaurants, Cheesesteaks, Poutineries         Aurora   \n",
              "3       Japanese, Fast Food, Food Court, Restaurants      Thornhill   \n",
              "4  Persian/Iranian, Turkish, Middle Eastern, Rest...  Richmond Hill   \n",
              "\n",
              "                                               hours  is_open   latitude  \\\n",
              "0  {'Monday': '11:30-14:30', 'Tuesday': '11:30-14...        1  40.110446   \n",
              "1                                                NaN        0  35.194894   \n",
              "2  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...        1  44.010962   \n",
              "3                                                NaN        1  43.820492   \n",
              "4  {'Tuesday': '12:0-21:0', 'Wednesday': '12:0-21...        1  43.947011   \n",
              "\n",
              "   longitude                 name postal_code  review_count state  \\\n",
              "0 -88.233073  The Empanadas House       61820             5    IL   \n",
              "1 -80.767442     Middle East Deli       28205             5    NC   \n",
              "2 -79.448677      Philthy Phillys     L4G 7J1             4    ON   \n",
              "3 -79.398466         Banzai Sushi     L3T 5W4             7    ON   \n",
              "4 -79.454862   Apadana Restaurant     L4E 1A5             3    ON   \n",
              "\n",
              "   business_stars  \n",
              "0             4.5  \n",
              "1             3.0  \n",
              "2             4.5  \n",
              "3             4.5  \n",
              "4             3.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxpt1dE76Vzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reviews dataframe needs .computer() to convert to df and takes some time\n",
        "rev = reviews.compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i53rpwIB8CiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "9ebf419c-8771-4371-8c58-35a07ade850a"
      },
      "source": [
        "rev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>reviews_stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ipufYjKx5saLVuDR6f6o0w</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-21 02:03:08</td>\n",
              "      <td>Was there with a girlfriend at lunch time toda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VNOhF-xUYguSjA01yx5nwA</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-08-20 17:46:40</td>\n",
              "      <td>I thought my meal was OK. I ordered an omelett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PMXYXphbbkx2TM80AtIpQQ</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-12-10 17:53:39</td>\n",
              "      <td>It's just a breakfast not too fancy. Weak coff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7hxilsquX34WXHYc80qLkw</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-09-02 18:54:37</td>\n",
              "      <td>Shoule be zero stars! So, we have been here a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Xnf39DsDWqiv1wulL2NK9g</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-30 05:33:08</td>\n",
              "      <td>I LOVE this place!!! I'm so happy they opened ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id             business_id  reviews_stars  \\\n",
              "index                                                                  \n",
              "0      ipufYjKx5saLVuDR6f6o0w  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "1      VNOhF-xUYguSjA01yx5nwA  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "2      PMXYXphbbkx2TM80AtIpQQ  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "3      7hxilsquX34WXHYc80qLkw  S9RoY_Smsh0a2JPo90bkdg              1   \n",
              "4      Xnf39DsDWqiv1wulL2NK9g  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "\n",
              "                     date                                               text  \n",
              "index                                                                         \n",
              "0     2017-08-21 02:03:08  Was there with a girlfriend at lunch time toda...  \n",
              "1     2017-08-20 17:46:40  I thought my meal was OK. I ordered an omelett...  \n",
              "2     2015-12-10 17:53:39  It's just a breakfast not too fancy. Weak coff...  \n",
              "3     2017-09-02 18:54:37  Shoule be zero stars! So, we have been here a ...  \n",
              "4     2017-04-30 05:33:08  I LOVE this place!!! I'm so happy they opened ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC10brfAASkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "1b2bb7c5-d5d8-4d8d-ee53-1c5d1c8cbe73"
      },
      "source": [
        "rev.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews_stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.055992e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.731101e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.394387e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviews_stars\n",
              "count   5.055992e+06\n",
              "mean    3.731101e+00\n",
              "std     1.394387e+00\n",
              "min     1.000000e+00\n",
              "25%     3.000000e+00\n",
              "50%     4.000000e+00\n",
              "75%     5.000000e+00\n",
              "max     5.000000e+00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYT37dleAUkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ff9b1bc4-8808-4fa1-9042-ebc1642bd277"
      },
      "source": [
        "rev.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['review_id', 'business_id', 'reviews_stars', 'date', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNaIh7QdAWpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "517abe63-40d1-4fa1-bb95-1069a2ba74d6"
      },
      "source": [
        "rev.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id                object\n",
              "business_id              object\n",
              "reviews_stars             int64\n",
              "date             datetime64[ns]\n",
              "text                     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-gvPdJSAXHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3ece41f2-d485-4794-ad48-8d647bae659f"
      },
      "source": [
        "rev.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5055992, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVggxyDiAXKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a9da6c21-ebc1-4e6d-d9ca-82a68f7e8106"
      },
      "source": [
        "rev.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>reviews_stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ipufYjKx5saLVuDR6f6o0w</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-21 02:03:08</td>\n",
              "      <td>Was there with a girlfriend at lunch time toda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id             business_id  reviews_stars  \\\n",
              "index                                                                  \n",
              "0      ipufYjKx5saLVuDR6f6o0w  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "\n",
              "                     date                                               text  \n",
              "index                                                                         \n",
              "0     2017-08-21 02:03:08  Was there with a girlfriend at lunch time toda...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I2FHfr2C9fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rev['text_length'] = rev['text'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bTbioE-DOrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "5f03e4e8-e573-45d5-a629-d394232f4f55"
      },
      "source": [
        "rev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>reviews_stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ipufYjKx5saLVuDR6f6o0w</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-21 02:03:08</td>\n",
              "      <td>Was there with a girlfriend at lunch time toda...</td>\n",
              "      <td>431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VNOhF-xUYguSjA01yx5nwA</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-08-20 17:46:40</td>\n",
              "      <td>I thought my meal was OK. I ordered an omelett...</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PMXYXphbbkx2TM80AtIpQQ</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-12-10 17:53:39</td>\n",
              "      <td>It's just a breakfast not too fancy. Weak coff...</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7hxilsquX34WXHYc80qLkw</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-09-02 18:54:37</td>\n",
              "      <td>Shoule be zero stars! So, we have been here a ...</td>\n",
              "      <td>3172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Xnf39DsDWqiv1wulL2NK9g</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-30 05:33:08</td>\n",
              "      <td>I LOVE this place!!! I'm so happy they opened ...</td>\n",
              "      <td>1031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id             business_id  reviews_stars  \\\n",
              "index                                                                  \n",
              "0      ipufYjKx5saLVuDR6f6o0w  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "1      VNOhF-xUYguSjA01yx5nwA  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "2      PMXYXphbbkx2TM80AtIpQQ  S9RoY_Smsh0a2JPo90bkdg              2   \n",
              "3      7hxilsquX34WXHYc80qLkw  S9RoY_Smsh0a2JPo90bkdg              1   \n",
              "4      Xnf39DsDWqiv1wulL2NK9g  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "\n",
              "                     date                                               text  \\\n",
              "index                                                                          \n",
              "0     2017-08-21 02:03:08  Was there with a girlfriend at lunch time toda...   \n",
              "1     2017-08-20 17:46:40  I thought my meal was OK. I ordered an omelett...   \n",
              "2     2015-12-10 17:53:39  It's just a breakfast not too fancy. Weak coff...   \n",
              "3     2017-09-02 18:54:37  Shoule be zero stars! So, we have been here a ...   \n",
              "4     2017-04-30 05:33:08  I LOVE this place!!! I'm so happy they opened ...   \n",
              "\n",
              "       text_length  \n",
              "index               \n",
              "0              431  \n",
              "1              280  \n",
              "2              340  \n",
              "3             3172  \n",
              "4             1031  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pbqIqXM0HJA",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment score for each Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKzsJXrz0cjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "83688a2e-c920-4383-efae-5408623e1ad0"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install vaderSentiment\n",
        "from nltk.corpus import wordnet \n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "\n",
        "nltk.download('wordnet')\n",
        "pd.options.display.max_rows = 999\n",
        "pd.options.display.max_columns = 999\n",
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxpL_WUF1jcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "9ac7ab7c-2db4-495b-a865-9f934829b739"
      },
      "source": [
        "df = rev\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>reviews_stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ipufYjKx5saLVuDR6f6o0w</td>\n",
              "      <td>S9RoY_Smsh0a2JPo90bkdg</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-21 02:03:08</td>\n",
              "      <td>Was there with a girlfriend at lunch time today. We both decided on breakfast. We both had their special combo; 2 eggs, 2 pancakes and a choice of a meat or bread or hash browns. I opted for meat so my meal came with 4 bacon strips. My friend got the toast. Great food and service. Coffee good also. Loved the fact that they gave us a pitcher of water and a carafe of coffee so we could indulged and not have to flag down a server.</td>\n",
              "      <td>431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    review_id             business_id  reviews_stars  \\\n",
              "index                                                                  \n",
              "0      ipufYjKx5saLVuDR6f6o0w  S9RoY_Smsh0a2JPo90bkdg              5   \n",
              "\n",
              "                     date  \\\n",
              "index                       \n",
              "0     2017-08-21 02:03:08   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
              "index                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "0      Was there with a girlfriend at lunch time today. We both decided on breakfast. We both had their special combo; 2 eggs, 2 pancakes and a choice of a meat or bread or hash browns. I opted for meat so my meal came with 4 bacon strips. My friend got the toast. Great food and service. Coffee good also. Loved the fact that they gave us a pitcher of water and a carafe of coffee so we could indulged and not have to flag down a server.   \n",
              "\n",
              "       text_length  \n",
              "index               \n",
              "0              431  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eidgcgDJ1cNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "#Add VADER metrics to dataframe\n",
        "df['compound'] = [analyzer.polarity_scores(v)['compound'] for v in df['text']]\n",
        "df['neg'] = [analyzer.polarity_scores(v)['neg'] for v in df['text']]\n",
        "df['neu'] = [analyzer.polarity_scores(v)['neu'] for v in df['text']]\n",
        "df['pos'] = [analyzer.polarity_scores(v)['pos'] for v in df['text']]\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPCOXBiR0SrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#do chunk by chunk like 5 different pandas dataframe. \n",
        "# train test split essentially"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63kLm8shviS",
        "colab_type": "text"
      },
      "source": [
        "# Previous Tally-ai Team Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i5reEYphyFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install vaderSentiment\n",
        "from nltk.corpus import wordnet \n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "\n",
        "# from tallylib.sql import getLatestReviews # for django app\n",
        "\n",
        "nltk.download('wordnet')\n",
        "pd.options.display.max_rows = 999\n",
        "pd.options.display.max_columns = 999\n",
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4wFqNZQhypU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = rev\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YZm1gB_EtW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[df['business_id'] == 'S9RoY_Smsh0a2JPo90bkdg'] # just work with one popular cafe\n",
        "\n",
        "def tokenizer(doc):\n",
        "     return [token for token in simple_preprocess(doc) \n",
        "             if token not in STOPWORDS]\n",
        "\n",
        "\n",
        "def related_to_food(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('food.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_service(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('service.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_speed(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('speed.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "def related_to_price(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('price.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_ambience(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('ambience.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_experience(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('experience.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "def extract_subject_related_words():\n",
        "  df['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
        "  df['cleaned'] = df['text'].apply(tokenizer)\n",
        "  df['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
        "  df['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
        "  df['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
        "  df['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
        "  df['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
        "  df['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
        "\n",
        "extract_subject_related_words()\n",
        "df.sample(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeOebL_hEtaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_list_reviews_containing_subject():\n",
        "  food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "  service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "  speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "  price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "  ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "  experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
        "  return food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
        "\n",
        "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
        "  # food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "  # service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "  # speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "  # price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "  # ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "  # experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOnKx2zHEtfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_score(sentence):\n",
        "    # Create a SentimentIntensityAnalyzer object. \n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "    return sentiment_dict\n",
        "\n",
        "def get_sentiment(review_list):\n",
        "    all_sentiments = []\n",
        "    compounds = []\n",
        "\n",
        "    if len(review_list) > 0:\n",
        "        for review in review_list:\n",
        "            score = sentiment_score(review)\n",
        "            all_sentiments.append(score)\n",
        "\n",
        "    if len(all_sentiments) > 0:\n",
        "        for sentiment_dict in all_sentiments:\n",
        "            compound = sentiment_dict['compound']\n",
        "            compounds.append(compound)\n",
        "\n",
        "    if len(compounds) > 0:\n",
        "        avg_sentiment = sum(compounds) / len(compounds)\n",
        "    \n",
        "    else:\n",
        "        avg_sentiment = None\n",
        "\n",
        "    return avg_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_wXc2m2EtlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_scores():\n",
        "  if len(food_review_list) > 0:\n",
        "    food_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
        "  else: \n",
        "    food_sentiment_score = 75\n",
        "  if len(service_review_list) > 0:\n",
        "    service_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
        "  else: \n",
        "    service_sentiment_score = 75\n",
        "  if len(speed_review_list) > 0:\n",
        "    speed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
        "  else: \n",
        "    speed_sentiment_score = 75\n",
        "  if len(price_review_list) > 0:\n",
        "    price_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
        "  else: \n",
        "    price_sentiment_score = 75\n",
        "  if len(ambience_review_list) > 0:\n",
        "    ambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
        "  else: \n",
        "    ambience_sentiment_score = 75\n",
        "  if len(experience_review_list) > 0:\n",
        "    experience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
        "  else: \n",
        "    experience_sentiment_score = 75\n",
        "  return food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
        "\n",
        "\n",
        "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGQomzbjEtrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "results = json.dumps([\n",
        "        { 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
        "        { 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
        "])\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi1Mf2KtqiMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_nodata2 = json.dumps([\n",
        "        { 'subject': 'Food', 'score': food_sentiment_score},\n",
        "        { 'subject': 'Service', 'score': service_sentiment_score},\n",
        "        { 'subject': 'Speed', 'score': speed_sentiment_score},\n",
        "        { 'subject': 'Price', 'score': price_sentiment_score},\n",
        "        { 'subject': 'Ambience', 'score': ambience_sentiment_score},\n",
        "        { 'subject': 'Experience', 'score': experience_sentiment_score}\n",
        "])\n",
        "results_nodata2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B31GysiEo0HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Radar graph here "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0vqCUwrxC9",
        "colab_type": "text"
      },
      "source": [
        "## TO DO & Tally-ai Sentiment.py File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qaCvUQVrRJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump the business csv and reviews parquet to postgres **which Anh is suppose to do\n",
        "# Run this notebook code on all reviews to get sentiment score and make postgres table -- set up columns for export sentiment table -- #EC2 Instance for python Vader script\n",
        "# Create dummy flask app and deploy it to elastic beanstalk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qLUaiHksW0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # # # # # # tallylib/sentiment.py # # # # # # # #\n",
        "\n",
        "# PIPELINE (While getting sentiment score and then do them all the same time)\n",
        "\n",
        "\n",
        "\n",
        "# import re\n",
        "# import nltk\n",
        "# import json\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# !pip install vaderSentiment\n",
        "# from nltk.corpus import wordnet \n",
        "# from gensim.utils import simple_preprocess\n",
        "# from gensim.parsing.preprocessing import STOPWORDS\n",
        "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "# import dask.dataframe as dd\n",
        "# import pandas as pd\n",
        "# !pip install fastparquet\n",
        "# from fastparquet import ParquetFile\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# from tallylib.sql import getLatestReviews\n",
        "\n",
        "\n",
        "reviews = dd.read_parquet('https://tally-ai-dspt3.s3.amazonaws.com/yelp-restaurants/reviews.parquet.gzip')\n",
        "reviews.head()\n",
        "rev = reviews.compute()\n",
        "df = rev\n",
        "\n",
        "\n",
        "df = df[df['business_id'] == 'S9RoY_Smsh0a2JPo90bkdg']# just work with one popular cafe\n",
        "\n",
        "\n",
        "def tokenizer(doc):\n",
        "\treturn [token for token in simple_preprocess(doc) \n",
        "\t\t\tif token not in STOPWORDS]\n",
        "\n",
        "\n",
        "def related_to_food(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('food.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_service(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('service.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "def related_to_speed(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_price(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('price.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_ambience(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_experience(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "def extract_subject_related_words():\n",
        "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
        "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
        "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
        "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
        "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
        "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
        "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
        "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
        "\n",
        "\n",
        "def get_list_reviews_containing_subject():\n",
        "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
        "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
        "\n",
        "\n",
        "\n",
        "def sentiment_score(sentence):\n",
        "\t# Create a SentimentIntensityAnalyzer object. \n",
        "\tsid_obj = SentimentIntensityAnalyzer()\n",
        "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
        "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "\treturn sentiment_dict\n",
        "\n",
        "\n",
        "def get_sentiment(review_list):\n",
        "\tall_sentiments = []\n",
        "\tcompounds = []\n",
        "\n",
        "\tif len(review_list) > 0:\n",
        "\t\tfor review in review_list:\n",
        "\t\t\tscore = sentiment_score(review)\n",
        "\t\t\tall_sentiments.append(score)\n",
        "\n",
        "\tif len(all_sentiments) > 0:\n",
        "\t\tfor sentiment_dict in all_sentiments:\n",
        "\t\t\tcompound = sentiment_dict['compound']\n",
        "\t\t\tcompounds.append(compound)\n",
        "\n",
        "\tif len(compounds) > 0:\n",
        "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
        "\t\n",
        "\telse:\n",
        "\t\tavg_sentiment = None\n",
        "\n",
        "\treturn avg_sentiment\n",
        "\n",
        "def get_scores():\n",
        "\tsubspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
        "\tscore_results = []\n",
        "\tfor subjectreviews in subspecreviews:\n",
        "\t\tif len(subjectreviews) > 0:\n",
        "\t\t\tsub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
        "\t\t\tif sub_sentiment_score < 0:\n",
        "\t\t\t\tsub_sentiment_score = 0\n",
        "\t\telse: \n",
        "\t\t\tsub_sentiment_score = 75\n",
        "\t\t\tscore_results.append(sub_sentiment_score)\n",
        "\treturn score_results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "extract_subject_related_words()\n",
        "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
        "subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
        "result = get_scores()\n",
        "\t\n",
        "# result = json.dumps([\n",
        "# \t\t\t{ 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
        "# \t\t\t{ 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
        "# ])\n",
        "\n",
        "# del [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
        "\n",
        "# \treturn result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO4MV1vkn0am",
        "colab_type": "text"
      },
      "source": [
        "# Vader W/ Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvnlw8sn7MA",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis\n",
        "- positive, negative, neutral and what that means with respect to those (trending, visualization, diving into what they love or dont love)\n",
        "- For Example: build week (salties hackers) using sentiment analysis to determine if a post was salty if it was subjective and negative "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCjvdbYmnzyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(rc={'figure.figsize':(30,1)})\n",
        "\n",
        "#helper function is heat map for each sentence\n",
        "def visualise_sentiments(data):\n",
        "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpyOFQ6woBRW",
        "colab_type": "text"
      },
      "source": [
        "## NLTK Vader\n",
        "- Vader sentiment, vaderSentiment on github (Valence Aware Dictionary aand sEntiment Reasoner) dictionary from social media on positivity and subjectivity\n",
        "- less than -.05 means negative sentiment greater than .5 means positive. neutral in between"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moh8TZ4LnzwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WgbHtaZrbwL",
        "colab_type": "text"
      },
      "source": [
        "## Negative Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcMAymcqhc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"I hate this place, it sucks, terrible service. negative negative negtive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hQrNmB0qpPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sid.polarity_scores(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdXyufORrQgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualise_sentiments(data):\n",
        "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")\n",
        "\n",
        "sentences = [\"I hate this place, it sucks, terrible service. negative negative negtive\"]\n",
        "\n",
        "for sentence in sentences:\n",
        "  visualise_sentiments({\n",
        "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
        "})\n",
        "\n",
        "#dictionary approach, only scores are like and dumb, also takes into account modifiers like 'really', 0's are just neutral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIFyC32orRV3",
        "colab_type": "text"
      },
      "source": [
        "## Positive Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLGEuQdWpKkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"We had a great breakfast that consisted of two omelettes They are very generous with the fillings and the hash browns and muffins were really good The service was also terrific:\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vue5VJjoEcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sid.polarity_scores(sentence)\n",
        "\n",
        "#compound is positive so it is a positive sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZwDqT9oEfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####want to print seperate images for several sentences but we are still working on it!!!!\n",
        "\n",
        "def visualise_sentiments_multiple(data):\n",
        "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")\n",
        "\n",
        "sentences = [\"We had a great breakfast that consisted of two omelettes They are very generous with the fillings and the hash browns and muffins were really good The service was also terrific\"]\n",
        "\n",
        "for sentence in sentences:\n",
        "  visualise_sentiments({\n",
        "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
        "})\n",
        "\n",
        "#dictionary approach, only scores are like and dumb, also takes into account modifiers like 'really', 0's are just neutral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maYKWCDfoKYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise_sentiments({\n",
        "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
        "})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pVc_eoCufmP",
        "colab_type": "text"
      },
      "source": [
        "## Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGsV7IQf8ICT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYV2UZPa8IKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python program to generate WordCloud \n",
        "  \n",
        "# importing all necessery modules \n",
        "from wordcloud import WordCloud, STOPWORDS \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "  \n",
        "# Reads 'S3' file  \n",
        "reviews = dd.read_parquet('https://tally-ai-dspt3.s3.amazonaws.com/yelp-restaurants/reviews.parquet.gzip')\n",
        "reviews.head()\n",
        "rev = reviews.compute()\n",
        "df = rev\n",
        "\n",
        "\n",
        "df = df[df['business_id'] == 'S9RoY_Smsh0a2JPo90bkdg']# just work with one popular cafe\n",
        "  \n",
        "comment_words = '' \n",
        "stopwords = set(STOPWORDS) \n",
        "  \n",
        "# iterate through the csv file \n",
        "for val in df.text: \n",
        "      \n",
        "    # typecaste each val to string \n",
        "    val = str(val) \n",
        "  \n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "      \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "      \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "  \n",
        "wordcloud = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white', \n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words) \n",
        "  \n",
        "# plot the WordCloud image                        \n",
        "plt.figure(figsize = (8, 8), facecolor = None) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "  \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}