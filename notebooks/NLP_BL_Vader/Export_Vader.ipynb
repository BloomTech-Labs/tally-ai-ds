{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to use dask\n",
    "1. Activate Conda Python 3 `source activate python3`\n",
    "2. Install fastparquet `conda install -c conda-forge fastparquet'\n",
    "3. Restart notebook kernal ensuring you are on conda_python3 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "from sagemaker import get_execution_role\n",
    "from fastparquet import ParquetFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='tally-ai-dspt3'\n",
    "folder = 'yelp-kaggle-raw-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data = 'final_combined.parquet.gzip'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, folder, data)\n",
    "df = dd.read_parquet(data_location)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dd to pd dataframe\n",
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df['datetime'].describe()\n",
    "# the timespan is about 14 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need name\n",
    "buisness_col = ['business_id', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars_review', 'review_count_reviews', 'categories']\n",
    "rev_col = ['review_id', 'business_id', 'stars_review', 'datetime', 'text']\n",
    "analytical_col = ['review_id', 'word_lenght']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-297b12c9fef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbiz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuisness_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbiz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "biz = pd.DataFrame(df, columns = buisness_col)\n",
    "biz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = pd.DataFrame(df, columns = rev_col)\n",
    "rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet \n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews # for django app\n",
    "\n",
    "nltk.download('wordnet')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "def tokenizer(doc):\n",
    "     return [token for token in simple_preprocess(doc) \n",
    "             if token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('food.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('service.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_speed(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('speed.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('price.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('ambience.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('experience.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "def extract_subject_related_words():\n",
    "  df['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "  df['cleaned'] = df['text'].apply(tokenizer)\n",
    "  df['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "  df['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "  df['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "  df['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "  df['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "  df['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "extract_subject_related_words()\n",
    "df.sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['words_related_to_food'].map(len) > 1) | (df['words_related_to_service'].map(len) > 1) | (df['words_related_to_speed'].map(len) > 1) | (df['words_related_to_price'].map(len) > 1) | (df['words_related_to_ambience'].map(len) > 1) | (df['words_related_to_experience'].map(len) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_reviews_containing_subject():\n",
    "  food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "  service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "  speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "  price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "  ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "  experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "  return food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
    "  # food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "  # service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "  # speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "  # price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "  # ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "  # experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object. \n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "    return sentiment_dict\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "    all_sentiments = []\n",
    "    compounds = []\n",
    "\n",
    "    if len(review_list) > 0:\n",
    "        for review in review_list:\n",
    "            score = sentiment_score(review)\n",
    "            all_sentiments.append(score)\n",
    "\n",
    "    if len(all_sentiments) > 0:\n",
    "        for sentiment_dict in all_sentiments:\n",
    "            compound = sentiment_dict['compound']\n",
    "            compounds.append(compound)\n",
    "\n",
    "    if len(compounds) > 0:\n",
    "        avg_sentiment = sum(compounds) / len(compounds)\n",
    "    \n",
    "    else:\n",
    "        avg_sentiment = None\n",
    "\n",
    "    return avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores():\n",
    "  if len(food_review_list) > 0:\n",
    "    food_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
    "  else: \n",
    "    food_sentiment_score = 75\n",
    "  if len(service_review_list) > 0:\n",
    "    service_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
    "  else: \n",
    "    service_sentiment_score = 75\n",
    "  if len(speed_review_list) > 0:\n",
    "    speed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
    "  else: \n",
    "    speed_sentiment_score = 75\n",
    "  if len(price_review_list) > 0:\n",
    "    price_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
    "  else: \n",
    "    price_sentiment_score = 75\n",
    "  if len(ambience_review_list) > 0:\n",
    "    ambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
    "  else: \n",
    "    ambience_sentiment_score = 75\n",
    "  if len(experience_review_list) > 0:\n",
    "    experience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
    "  else: \n",
    "    experience_sentiment_score = 75\n",
    "  return food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
    "\n",
    "\n",
    "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.dumps([\n",
    "        { 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
    "        { 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
    "])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')# region can be any choose one close to you below\n",
    "# # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html\n",
    "                \n",
    "# text = l7\n",
    "# print(json.dumps(comprehend.batch_detect_sentiment(TextList=text, LanguageCode='en'), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from nltk.corpus import wordnet \n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews\n",
    "\n",
    "\n",
    "# def yelpReviewSentiment(business_id):\n",
    "# \tdata = getLatestReviews(business_id, limit=200)\n",
    "# \tif len(data)==0:\n",
    "# \t\treturn {}\n",
    "# \tdf = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "# \tdel data\n",
    "\n",
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "\n",
    "def tokenizer(doc):\n",
    "\treturn [token for token in simple_preprocess(doc) \n",
    "\t\t\tif token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('food.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('service.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "def related_to_speed(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('price.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "def extract_subject_related_words():\n",
    "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
    "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "\n",
    "def get_list_reviews_containing_subject():\n",
    "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_score(sentence):\n",
    "\t# Create a SentimentIntensityAnalyzer object. \n",
    "\tsid_obj = SentimentIntensityAnalyzer()\n",
    "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "\treturn sentiment_dict\n",
    "\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "\tall_sentiments = []\n",
    "\tcompounds = []\n",
    "\n",
    "\tif len(review_list) > 0:\n",
    "\t\tfor review in review_list:\n",
    "\t\t\tscore = sentiment_score(review)\n",
    "\t\t\tall_sentiments.append(score)\n",
    "\n",
    "\tif len(all_sentiments) > 0:\n",
    "\t\tfor sentiment_dict in all_sentiments:\n",
    "\t\t\tcompound = sentiment_dict['compound']\n",
    "\t\t\tcompounds.append(compound)\n",
    "\n",
    "\tif len(compounds) > 0:\n",
    "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
    "\t\n",
    "\telse:\n",
    "\t\tavg_sentiment = None\n",
    "\n",
    "\treturn avg_sentiment\n",
    "\n",
    "\n",
    "# # tallylib/sentiment.py\n",
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from nltk.corpus import wordnet \n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews\n",
    "\n",
    "\n",
    "# def yelpReviewSentiment(business_id):\n",
    "# \tdata = getLatestReviews(business_id, limit=200)\n",
    "# \tif len(data)==0:\n",
    "# \t\treturn {}\n",
    "# \tdf = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "# \tdel data\n",
    "\n",
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "\n",
    "def tokenizer(doc):\n",
    "\treturn [token for token in simple_preprocess(doc) \n",
    "\t\t\tif token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('food.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('service.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_speed(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('price.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def extract_subject_related_words():\n",
    "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
    "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "\n",
    "def get_list_reviews_containing_subject():\n",
    "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_score(sentence):\n",
    "\t# Create a SentimentIntensityAnalyzer object. \n",
    "\tsid_obj = SentimentIntensityAnalyzer()\n",
    "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "\treturn sentiment_dict\n",
    "\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "\tall_sentiments = []\n",
    "\tcompounds = []\n",
    "\n",
    "\tif len(review_list) > 0:\n",
    "\t\tfor review in review_list:\n",
    "\t\t\tscore = sentiment_score(review)\n",
    "\t\t\tall_sentiments.append(score)\n",
    "\n",
    "\tif len(all_sentiments) > 0:\n",
    "\t\tfor sentiment_dict in all_sentiments:\n",
    "\t\t\tcompound = sentiment_dict['compound']\n",
    "\t\t\tcompounds.append(compound)\n",
    "\n",
    "\tif len(compounds) > 0:\n",
    "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
    "\t\n",
    "\telse:\n",
    "\t\tavg_sentiment = None\n",
    "\n",
    "\treturn avg_sentiment\n",
    "\n",
    "\n",
    "# def get_scores():\n",
    "# \tif len(food_review_list) > 0:\n",
    "# \t\tfood_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
    "# \t\tif food_sentiment_score < 0:\n",
    "# \t\t\tfood_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tfood_sentiment_score = 75\n",
    "# \tif len(service_review_list) > 0:\n",
    "# \t\tservice_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
    "# \t\tif service_sentiment_score < 0:\n",
    "# \t\t\tservice_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tservice_sentiment_score = 75\n",
    "# \tif len(speed_review_list) > 0:\n",
    "# \t\tspeed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
    "# \t\tif speed_sentiment_score < 0:\n",
    "# \t\t\tspeed_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tspeed_sentiment_score = 75\n",
    "# \tif len(price_review_list) > 0:\n",
    "# \t\tprice_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
    "# \t\tif price_sentiment_score < 0:\n",
    "# \t\t\tprice_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tprice_sentiment_score = 75\n",
    "# \tif len(ambience_review_list) > 0:\n",
    "# \t\tambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
    "# \t\tif ambience_sentiment_score < 0:\n",
    "# \t\t\tambience_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tambience_sentiment_score = 75\n",
    "# \tif len(experience_review_list) > 0:\n",
    "# \t\texperience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
    "# \t\tif experience_sentiment_score < 0:\n",
    "# \t\t\texperience_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\texperience_sentiment_score = 75\n",
    "# \treturn food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
    "\n",
    "def get_scores():\n",
    "\tsubspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "\tscore_results = []\n",
    "\tfor subjectreviews in subspecreviews:\n",
    "\t\tif len(subjectreviews) > 0:\n",
    "\t\t\tsub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
    "\t\t\tif sub_sentiment_score < 0:\n",
    "\t\t\t\tsub_sentiment_score = 0\n",
    "\t\telse: \n",
    "\t\t\tsub_sentiment_score = 75\n",
    "\t\t\tscore_results.append(sub_sentiment_score)\n",
    "\treturn score_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extract_subject_related_words()\n",
    "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
    "subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "result = get_scores()\n",
    "\t\n",
    "    \n",
    "    # result = json.dumps([\n",
    "# \t\t\t{ 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
    "# \t\t\t{ 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
    "# ])\n",
    "\n",
    "# del [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
    "\n",
    "# \treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Thoughts on condensing function\n",
    "\n",
    "# scoreslist = [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
    "# for score in scoreslist:\n",
    "#   viztype4 = {\n",
    "#       'subject': 'Food', 'data1': scoreslist[0], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Service', 'data1': scoreslist[1], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Speed', 'data1': scoreslist[2], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Price', 'data1': scoreslist[3], 'data2': 0, 'maxValue': 150 },     \n",
    "#       'subject': 'Ambience', 'data1': scoreslist[4], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Experience', 'data1': scoreslist[5], 'data2': 0, 'maxValue': 150 },   \n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sample\n",
    "# [\n",
    "#         { subject: 'Subject 1', data1: 45, data2: 70, maxValue: 150 },\n",
    "#         { subject: 'Subject 2', data1: 75, data2: 95, maxValue: 150 },\n",
    "#         { subject: 'Subject 3', data1: 20, data2: 50, maxValue: 150 },\n",
    "#         { subject: 'Example Subject 4', data1: 65, data2: 85, maxValue: 150 },\n",
    "#         { subject: 'Food', data1: 35, data2: 45, maxValue: 150}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores():\n",
    "  subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "  score_results = []\n",
    "  for subjectreviews in subspecreviews:\n",
    "    if len(subjectreviews) > 0:\n",
    "      sub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
    "      if sub_sentiment_score < 0:\n",
    "        sub_sentiment_score = 0\n",
    "    else: \n",
    "      sub_sentiment_score = 75\n",
    "    score_results.append(sub_sentiment_score)\n",
    "  return score_results\n",
    "[food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score] = get_scores()\n",
    "food_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic = pd.DataFrame(df, columns = buisness_col)\n",
    "analytic.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
