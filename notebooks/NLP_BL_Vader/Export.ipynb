{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to use dask\n",
    "1. Activate Conda Python 3 `source activate python3`\n",
    "2. Install fastparquet `conda install -c conda-forge fastparquet'\n",
    "3. Restart notebook kernal ensuring you are on conda_python3 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "from sagemaker import get_execution_role\n",
    "from fastparquet import ParquetFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='tally-ai-dspt3'\n",
    "folder = 'yelp-kaggle-raw-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "      <th>stars_business</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>name_users</th>\n",
       "      <th>review_count_users</th>\n",
       "      <th>cool_users</th>\n",
       "      <th>funny_users</th>\n",
       "      <th>useful_users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3175 Rutherford Rd, Unit 47</td>\n",
       "      <td>E7v9sMJx4_Swx7VtymNt5Q</td>\n",
       "      <td>Food Delivery Services, Food, Thai, Restaurants</td>\n",
       "      <td>Vaughan</td>\n",
       "      <td>1</td>\n",
       "      <td>43.827830</td>\n",
       "      <td>-79.538072</td>\n",
       "      <td>L4K 5Y6</td>\n",
       "      <td>ON</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-06-22 21:48:15</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777 Steeles Avenue W</td>\n",
       "      <td>4Lh1lZXTf0EoNqdzT60GPQ</td>\n",
       "      <td>Coffee &amp; Tea, Food, Ice Cream &amp; Frozen Yogurt,...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>43.782160</td>\n",
       "      <td>-79.490430</td>\n",
       "      <td>M3J 3K5</td>\n",
       "      <td>ON</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-06-22 21:48:15</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11155 S Eastern Ave</td>\n",
       "      <td>RPjBB_uhHQ4oxp39Jqm_HQ</td>\n",
       "      <td>Sandwiches, Restaurants</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>1</td>\n",
       "      <td>35.989803</td>\n",
       "      <td>-115.101597</td>\n",
       "      <td>89052</td>\n",
       "      <td>NV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...</td>\n",
       "      <td>2013-02-08 21:54:49</td>\n",
       "      <td>Jake</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140 S Green Valley Pkwy, Ste 142</td>\n",
       "      <td>SR0Q2hAEMJ_m23O_x-khSQ</td>\n",
       "      <td>Restaurants, American (New), Gluten-Free, Vege...</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>0</td>\n",
       "      <td>36.022441</td>\n",
       "      <td>-115.083539</td>\n",
       "      <td>89012</td>\n",
       "      <td>NV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...</td>\n",
       "      <td>2013-02-08 21:54:49</td>\n",
       "      <td>Jake</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8174 S Las Vegas Blvd, Ste 101</td>\n",
       "      <td>V_TxEdzeEs8P5nGPANOY7A</td>\n",
       "      <td>Cocktail Bars, Gay Bars, Cafes, Bars, Nightlif...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>0</td>\n",
       "      <td>36.040642</td>\n",
       "      <td>-115.170643</td>\n",
       "      <td>89123</td>\n",
       "      <td>NV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...</td>\n",
       "      <td>2013-02-08 21:54:49</td>\n",
       "      <td>Jake</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                address             business_id  \\\n",
       "index                                                             \n",
       "0           3175 Rutherford Rd, Unit 47  E7v9sMJx4_Swx7VtymNt5Q   \n",
       "1                 2777 Steeles Avenue W  4Lh1lZXTf0EoNqdzT60GPQ   \n",
       "2                   11155 S Eastern Ave  RPjBB_uhHQ4oxp39Jqm_HQ   \n",
       "3      140 S Green Valley Pkwy, Ste 142  SR0Q2hAEMJ_m23O_x-khSQ   \n",
       "4        8174 S Las Vegas Blvd, Ste 101  V_TxEdzeEs8P5nGPANOY7A   \n",
       "\n",
       "                                              categories       city  is_open  \\\n",
       "index                                                                          \n",
       "0        Food Delivery Services, Food, Thai, Restaurants    Vaughan        1   \n",
       "1      Coffee & Tea, Food, Ice Cream & Frozen Yogurt,...    Toronto        0   \n",
       "2                                Sandwiches, Restaurants  Henderson        1   \n",
       "3      Restaurants, American (New), Gluten-Free, Vege...  Henderson        0   \n",
       "4      Cocktail Bars, Gay Bars, Cafes, Bars, Nightlif...  Las Vegas        0   \n",
       "\n",
       "        latitude   longitude postal_code state  stars_business  ...  \\\n",
       "index                                                           ...   \n",
       "0      43.827830  -79.538072     L4K 5Y6    ON             4.0  ...   \n",
       "1      43.782160  -79.490430     M3J 3K5    ON             4.0  ...   \n",
       "2      35.989803 -115.101597       89052    NV             3.0  ...   \n",
       "3      36.022441 -115.083539       89012    NV             4.0  ...   \n",
       "4      36.040642 -115.170643       89123    NV             3.5  ...   \n",
       "\n",
       "      compliment_writer elite fans  \\\n",
       "index                                \n",
       "0                     0          0   \n",
       "1                     0          0   \n",
       "2                     0          1   \n",
       "3                     0          1   \n",
       "4                     0          1   \n",
       "\n",
       "                                                 friends        yelping_since  \\\n",
       "index                                                                           \n",
       "0                                                   None  2011-06-22 21:48:15   \n",
       "1                                                   None  2011-06-22 21:48:15   \n",
       "2      CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...  2013-02-08 21:54:49   \n",
       "3      CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...  2013-02-08 21:54:49   \n",
       "4      CyOjizbfMb2hxkLIwE76Ow, MbZ0W9PjmlI7J9fs4SiNrw...  2013-02-08 21:54:49   \n",
       "\n",
       "       name_users review_count_users  cool_users  funny_users  useful_users  \n",
       "index                                                                        \n",
       "0               F                  4           2            0             6  \n",
       "1               F                  4           2            0             6  \n",
       "2            Jake                 50          17           17            53  \n",
       "3            Jake                 50          17           17            53  \n",
       "4            Jake                 50          17           17            53  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "data = 'final_combined.parquet.gzip'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, folder, data)\n",
    "df = dd.read_parquet(data_location)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dd to pd dataframe\n",
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 5055992\n",
       "unique                4988798\n",
       "top       2014-07-28 05:36:33\n",
       "freq                        7\n",
       "first     2004-10-12 10:13:32\n",
       "last      2019-12-13 15:50:49\n",
       "Name: datetime, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df['datetime'].describe()\n",
    "# the timespan is about 14 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need name\n",
    "buisness_col = ['business_id', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars_review', 'review_count_reviews', 'categories']\n",
    "rev_col = ['review_id', 'business_id', 'stars_review', 'datetime', 'text']\n",
    "analytical_col = ['review_id', 'word_lenght']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_review</th>\n",
       "      <th>review_count_reviews</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E7v9sMJx4_Swx7VtymNt5Q</td>\n",
       "      <td>3175 Rutherford Rd, Unit 47</td>\n",
       "      <td>Vaughan</td>\n",
       "      <td>ON</td>\n",
       "      <td>L4K 5Y6</td>\n",
       "      <td>43.827830</td>\n",
       "      <td>-79.538072</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>Food Delivery Services, Food, Thai, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4Lh1lZXTf0EoNqdzT60GPQ</td>\n",
       "      <td>2777 Steeles Avenue W</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>M3J 3K5</td>\n",
       "      <td>43.782160</td>\n",
       "      <td>-79.490430</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Coffee &amp; Tea, Food, Ice Cream &amp; Frozen Yogurt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RPjBB_uhHQ4oxp39Jqm_HQ</td>\n",
       "      <td>11155 S Eastern Ave</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>89052</td>\n",
       "      <td>35.989803</td>\n",
       "      <td>-115.101597</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>Sandwiches, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SR0Q2hAEMJ_m23O_x-khSQ</td>\n",
       "      <td>140 S Green Valley Pkwy, Ste 142</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>89012</td>\n",
       "      <td>36.022441</td>\n",
       "      <td>-115.083539</td>\n",
       "      <td>4</td>\n",
       "      <td>525</td>\n",
       "      <td>Restaurants, American (New), Gluten-Free, Vege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V_TxEdzeEs8P5nGPANOY7A</td>\n",
       "      <td>8174 S Las Vegas Blvd, Ste 101</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89123</td>\n",
       "      <td>36.040642</td>\n",
       "      <td>-115.170643</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>Cocktail Bars, Gay Bars, Cafes, Bars, Nightlif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id                           address       city  \\\n",
       "index                                                                        \n",
       "0      E7v9sMJx4_Swx7VtymNt5Q       3175 Rutherford Rd, Unit 47    Vaughan   \n",
       "1      4Lh1lZXTf0EoNqdzT60GPQ             2777 Steeles Avenue W    Toronto   \n",
       "2      RPjBB_uhHQ4oxp39Jqm_HQ               11155 S Eastern Ave  Henderson   \n",
       "3      SR0Q2hAEMJ_m23O_x-khSQ  140 S Green Valley Pkwy, Ste 142  Henderson   \n",
       "4      V_TxEdzeEs8P5nGPANOY7A    8174 S Las Vegas Blvd, Ste 101  Las Vegas   \n",
       "\n",
       "      state postal_code   latitude   longitude  stars_review  \\\n",
       "index                                                          \n",
       "0        ON     L4K 5Y6  43.827830  -79.538072             5   \n",
       "1        ON     M3J 3K5  43.782160  -79.490430             4   \n",
       "2        NV       89052  35.989803 -115.101597             2   \n",
       "3        NV       89012  36.022441 -115.083539             4   \n",
       "4        NV       89123  36.040642 -115.170643             5   \n",
       "\n",
       "       review_count_reviews                                         categories  \n",
       "index                                                                           \n",
       "0                       125    Food Delivery Services, Food, Thai, Restaurants  \n",
       "1                        22  Coffee & Tea, Food, Ice Cream & Frozen Yogurt,...  \n",
       "2                        95                            Sandwiches, Restaurants  \n",
       "3                       525  Restaurants, American (New), Gluten-Free, Vege...  \n",
       "4                       127  Cocktail Bars, Gay Bars, Cafes, Bars, Nightlif...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz = pd.DataFrame(df, columns = buisness_col)\n",
    "biz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055992, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'biz-onepart'\n",
    "folder = 'biz-rev-analytic'\n",
    "bucket = 'tally-ai-dspt3'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, folder, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://tally-ai-dspt3/biz-rev-analytic/biz-onepart\n"
     ]
    }
   ],
   "source": [
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previously did 5 partitions\n",
    "#now trying 1 partition\n",
    "biz = dd.from_pandas(biz, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tally-ai-dspt3/biz-rev-analytic/biz/0.part']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly save to S3 bucket\n",
    "# make utility function to load and save data\n",
    "\n",
    "\n",
    "\n",
    "dd.to_csv(biz, 's3://tally-ai-dspt3/biz-rev-analytic/biz-one-part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read \n",
    "biz = dd.read_csv('s3://tally-ai-dspt3/biz-rev-analytic/rev.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_review</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TqVu_UhFlbrX7N-NFm3Kwg</td>\n",
       "      <td>E7v9sMJx4_Swx7VtymNt5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-06-23 00:52:30</td>\n",
       "      <td>Had duck curry, coconut rice and Thai style pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he__NcybQ58xBqOjd3DCaw</td>\n",
       "      <td>4Lh1lZXTf0EoNqdzT60GPQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-19 23:24:55</td>\n",
       "      <td>First time here (thanks Groupon!).  Big burger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_uXQHRbF7eygy7eVk268tg</td>\n",
       "      <td>RPjBB_uhHQ4oxp39Jqm_HQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-02-19 20:40:15</td>\n",
       "      <td>Hate to do this to this place but as I write t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BO7NZvQ8sXDfxyiaOhMa1A</td>\n",
       "      <td>SR0Q2hAEMJ_m23O_x-khSQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-07-15 18:24:45</td>\n",
       "      <td>First off I am giving an extra star for clean,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Q7K1WVpM-aBaVB-8PEoQA</td>\n",
       "      <td>V_TxEdzeEs8P5nGPANOY7A</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-03-19 12:40:11</td>\n",
       "      <td>Went in here for lunch yesterday to try it out...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    review_id             business_id  stars_review  \\\n",
       "index                                                                 \n",
       "0      TqVu_UhFlbrX7N-NFm3Kwg  E7v9sMJx4_Swx7VtymNt5Q             5   \n",
       "1      he__NcybQ58xBqOjd3DCaw  4Lh1lZXTf0EoNqdzT60GPQ             4   \n",
       "2      _uXQHRbF7eygy7eVk268tg  RPjBB_uhHQ4oxp39Jqm_HQ             2   \n",
       "3      BO7NZvQ8sXDfxyiaOhMa1A  SR0Q2hAEMJ_m23O_x-khSQ             4   \n",
       "4      -Q7K1WVpM-aBaVB-8PEoQA  V_TxEdzeEs8P5nGPANOY7A             5   \n",
       "\n",
       "                 datetime                                               text  \n",
       "index                                                                         \n",
       "0     2011-06-23 00:52:30  Had duck curry, coconut rice and Thai style pa...  \n",
       "1     2016-01-19 23:24:55  First time here (thanks Groupon!).  Big burger...  \n",
       "2     2014-02-19 20:40:15  Hate to do this to this place but as I write t...  \n",
       "3     2014-07-15 18:24:45  First off I am giving an extra star for clean,...  \n",
       "4     2015-03-19 12:40:11  Went in here for lunch yesterday to try it out...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = pd.DataFrame(df, columns = rev_col)\n",
    "rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be a pandas DataFrame or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0c2dd7b46e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/dask/dataframe/io/io.py\u001b[0m in \u001b[0;36mfrom_pandas\u001b[0;34m(data, npartitions, chunksize, sort, name)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a pandas DataFrame or Series\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpartitions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input must be a pandas DataFrame or Series"
     ]
    }
   ],
   "source": [
    "rev = dd.from_pandas(rev, npartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tally-ai-dspt3/biz-rev-analytic/rev.csv/0.part',\n",
       " 'tally-ai-dspt3/biz-rev-analytic/rev.csv/1.part',\n",
       " 'tally-ai-dspt3/biz-rev-analytic/rev.csv/2.part',\n",
       " 'tally-ai-dspt3/biz-rev-analytic/rev.csv/3.part',\n",
       " 'tally-ai-dspt3/biz-rev-analytic/rev.csv/4.part']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly save to S3 bucket\n",
    "# make utility function to load and save data\n",
    "\n",
    "\n",
    "\n",
    "dd.to_csv(rev, 's3://tally-ai-dspt3/biz-rev-analytic/rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = dd.read_csv('taally_S3_bucketlink', np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = dd.read_csv('s3://tally-ai-dspt3/biz-rev-analytic/rev.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traaining job or python script in background (could turn off instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim and Vader need to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to use Gensim\n",
    "1. Activate Conda Python 3 `source activate python3`\n",
    "2. Install Gensim `conda install -c conda-forge gensim'\n",
    "3. Restart notebook kernal ensuring you are on conda_python3 environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to use Vader\n",
    "1. pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ece80696d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet \n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews # for django app\n",
    "\n",
    "nltk.download('wordnet')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "def tokenizer(doc):\n",
    "     return [token for token in simple_preprocess(doc) \n",
    "             if token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('food.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('service.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_speed(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('speed.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('price.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('ambience.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "  word_similarity_list = []\n",
    "  for review_word in doc:\n",
    "    syns = wordnet.synsets(review_word) \n",
    "    if len(syns) > 0:\n",
    "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "      w2 = wordnet.synset('experience.n.01') \n",
    "      word_similarity_score = w1.wup_similarity(w2)\n",
    "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "        word_similarity_list.append(review_word)\n",
    "  return word_similarity_list\n",
    "\n",
    "def extract_subject_related_words():\n",
    "  df['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "  df['cleaned'] = df['text'].apply(tokenizer)\n",
    "  df['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "  df['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "  df['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "  df['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "  df['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "  df['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "extract_subject_related_words()\n",
    "df.sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['words_related_to_food'].map(len) > 1) | (df['words_related_to_service'].map(len) > 1) | (df['words_related_to_speed'].map(len) > 1) | (df['words_related_to_price'].map(len) > 1) | (df['words_related_to_ambience'].map(len) > 1) | (df['words_related_to_experience'].map(len) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_reviews_containing_subject():\n",
    "  food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "  service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "  speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "  price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "  ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "  experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "  return food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
    "  # food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "  # service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "  # speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "  # price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "  # ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "  # experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentiment Score (also very slow here) \n",
    "## Make EC2 instance and see what happens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object. \n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "    return sentiment_dict\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "    all_sentiments = []\n",
    "    compounds = []\n",
    "\n",
    "    if len(review_list) > 0:\n",
    "        for review in review_list:\n",
    "            score = sentiment_score(review)\n",
    "            all_sentiments.append(score)\n",
    "\n",
    "    if len(all_sentiments) > 0:\n",
    "        for sentiment_dict in all_sentiments:\n",
    "            compound = sentiment_dict['compound']\n",
    "            compounds.append(compound)\n",
    "\n",
    "    if len(compounds) > 0:\n",
    "        avg_sentiment = sum(compounds) / len(compounds)\n",
    "    \n",
    "    else:\n",
    "        avg_sentiment = None\n",
    "\n",
    "    return avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores():\n",
    "  if len(food_review_list) > 0:\n",
    "    food_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
    "  else: \n",
    "    food_sentiment_score = 75\n",
    "  if len(service_review_list) > 0:\n",
    "    service_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
    "  else: \n",
    "    service_sentiment_score = 75\n",
    "  if len(speed_review_list) > 0:\n",
    "    speed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
    "  else: \n",
    "    speed_sentiment_score = 75\n",
    "  if len(price_review_list) > 0:\n",
    "    price_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
    "  else: \n",
    "    price_sentiment_score = 75\n",
    "  if len(ambience_review_list) > 0:\n",
    "    ambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
    "  else: \n",
    "    ambience_sentiment_score = 75\n",
    "  if len(experience_review_list) > 0:\n",
    "    experience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
    "  else: \n",
    "    experience_sentiment_score = 75\n",
    "  return food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
    "\n",
    "\n",
    "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.dumps([\n",
    "        { 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "        { 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
    "        { 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
    "])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')# region can be any choose one close to you below\n",
    "# # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html\n",
    "                \n",
    "# text = l7\n",
    "# print(json.dumps(comprehend.batch_detect_sentiment(TextList=text, LanguageCode='en'), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from nltk.corpus import wordnet \n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews\n",
    "\n",
    "\n",
    "# def yelpReviewSentiment(business_id):\n",
    "# \tdata = getLatestReviews(business_id, limit=200)\n",
    "# \tif len(data)==0:\n",
    "# \t\treturn {}\n",
    "# \tdf = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "# \tdel data\n",
    "\n",
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "\n",
    "def tokenizer(doc):\n",
    "\treturn [token for token in simple_preprocess(doc) \n",
    "\t\t\tif token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('food.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('service.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "def related_to_speed(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('price.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "def extract_subject_related_words():\n",
    "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
    "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "\n",
    "def get_list_reviews_containing_subject():\n",
    "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_score(sentence):\n",
    "\t# Create a SentimentIntensityAnalyzer object. \n",
    "\tsid_obj = SentimentIntensityAnalyzer()\n",
    "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "\treturn sentiment_dict\n",
    "\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "\tall_sentiments = []\n",
    "\tcompounds = []\n",
    "\n",
    "\tif len(review_list) > 0:\n",
    "\t\tfor review in review_list:\n",
    "\t\t\tscore = sentiment_score(review)\n",
    "\t\t\tall_sentiments.append(score)\n",
    "\n",
    "\tif len(all_sentiments) > 0:\n",
    "\t\tfor sentiment_dict in all_sentiments:\n",
    "\t\t\tcompound = sentiment_dict['compound']\n",
    "\t\t\tcompounds.append(compound)\n",
    "\n",
    "\tif len(compounds) > 0:\n",
    "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
    "\t\n",
    "\telse:\n",
    "\t\tavg_sentiment = None\n",
    "\n",
    "\treturn avg_sentiment\n",
    "\n",
    "\n",
    "# # tallylib/sentiment.py\n",
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from nltk.corpus import wordnet \n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "# from tallylib.sql import getLatestReviews\n",
    "\n",
    "\n",
    "# def yelpReviewSentiment(business_id):\n",
    "# \tdata = getLatestReviews(business_id, limit=200)\n",
    "# \tif len(data)==0:\n",
    "# \t\treturn {}\n",
    "# \tdf = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "# \tdel data\n",
    "\n",
    "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
    "#command ran in database\n",
    "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
    "\n",
    "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
    "\n",
    "\n",
    "def tokenizer(doc):\n",
    "\treturn [token for token in simple_preprocess(doc) \n",
    "\t\t\tif token not in STOPWORDS]\n",
    "\n",
    "\n",
    "def related_to_food(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('food.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_service(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('service.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_speed(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_price(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('price.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_ambience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def related_to_experience(doc):\n",
    "\tword_similarity_list = []\n",
    "\tfor review_word in doc:\n",
    "\t\tsyns = wordnet.synsets(review_word) \n",
    "\t\tif len(syns) > 0:\n",
    "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
    "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
    "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
    "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
    "\t\t\t\tword_similarity_list.append(review_word)\n",
    "\treturn word_similarity_list\n",
    "\n",
    "\n",
    "def extract_subject_related_words():\n",
    "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
    "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
    "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
    "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
    "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
    "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
    "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
    "\n",
    "\n",
    "def get_list_reviews_containing_subject():\n",
    "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
    "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
    "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
    "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
    "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
    "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
    "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_score(sentence):\n",
    "\t# Create a SentimentIntensityAnalyzer object. \n",
    "\tsid_obj = SentimentIntensityAnalyzer()\n",
    "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
    "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "\treturn sentiment_dict\n",
    "\n",
    "\n",
    "def get_sentiment(review_list):\n",
    "\tall_sentiments = []\n",
    "\tcompounds = []\n",
    "\n",
    "\tif len(review_list) > 0:\n",
    "\t\tfor review in review_list:\n",
    "\t\t\tscore = sentiment_score(review)\n",
    "\t\t\tall_sentiments.append(score)\n",
    "\n",
    "\tif len(all_sentiments) > 0:\n",
    "\t\tfor sentiment_dict in all_sentiments:\n",
    "\t\t\tcompound = sentiment_dict['compound']\n",
    "\t\t\tcompounds.append(compound)\n",
    "\n",
    "\tif len(compounds) > 0:\n",
    "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
    "\t\n",
    "\telse:\n",
    "\t\tavg_sentiment = None\n",
    "\n",
    "\treturn avg_sentiment\n",
    "\n",
    "\n",
    "# def get_scores():\n",
    "# \tif len(food_review_list) > 0:\n",
    "# \t\tfood_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
    "# \t\tif food_sentiment_score < 0:\n",
    "# \t\t\tfood_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tfood_sentiment_score = 75\n",
    "# \tif len(service_review_list) > 0:\n",
    "# \t\tservice_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
    "# \t\tif service_sentiment_score < 0:\n",
    "# \t\t\tservice_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tservice_sentiment_score = 75\n",
    "# \tif len(speed_review_list) > 0:\n",
    "# \t\tspeed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
    "# \t\tif speed_sentiment_score < 0:\n",
    "# \t\t\tspeed_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tspeed_sentiment_score = 75\n",
    "# \tif len(price_review_list) > 0:\n",
    "# \t\tprice_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
    "# \t\tif price_sentiment_score < 0:\n",
    "# \t\t\tprice_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tprice_sentiment_score = 75\n",
    "# \tif len(ambience_review_list) > 0:\n",
    "# \t\tambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
    "# \t\tif ambience_sentiment_score < 0:\n",
    "# \t\t\tambience_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\tambience_sentiment_score = 75\n",
    "# \tif len(experience_review_list) > 0:\n",
    "# \t\texperience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
    "# \t\tif experience_sentiment_score < 0:\n",
    "# \t\t\texperience_sentiment_score = 0\n",
    "# \telse: \n",
    "# \t\texperience_sentiment_score = 75\n",
    "# \treturn food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
    "\n",
    "def get_scores():\n",
    "\tsubspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "\tscore_results = []\n",
    "\tfor subjectreviews in subspecreviews:\n",
    "\t\tif len(subjectreviews) > 0:\n",
    "\t\t\tsub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
    "\t\t\tif sub_sentiment_score < 0:\n",
    "\t\t\t\tsub_sentiment_score = 0\n",
    "\t\telse: \n",
    "\t\t\tsub_sentiment_score = 75\n",
    "\t\t\tscore_results.append(sub_sentiment_score)\n",
    "\treturn score_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extract_subject_related_words()\n",
    "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
    "subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "result = get_scores()\n",
    "\t\n",
    "    \n",
    "    # result = json.dumps([\n",
    "# \t\t\t{ 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
    "# \t\t\t{ 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
    "# \t\t\t{ 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
    "# ])\n",
    "\n",
    "# del [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
    "\n",
    "# \treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Thoughts on condensing function\n",
    "\n",
    "# scoreslist = [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
    "# for score in scoreslist:\n",
    "#   viztype4 = {\n",
    "#       'subject': 'Food', 'data1': scoreslist[0], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Service', 'data1': scoreslist[1], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Speed', 'data1': scoreslist[2], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Price', 'data1': scoreslist[3], 'data2': 0, 'maxValue': 150 },     \n",
    "#       'subject': 'Ambience', 'data1': scoreslist[4], 'data2': 0, 'maxValue': 150 },\n",
    "#       'subject': 'Experience', 'data1': scoreslist[5], 'data2': 0, 'maxValue': 150 },   \n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sample\n",
    "# [\n",
    "#         { subject: 'Subject 1', data1: 45, data2: 70, maxValue: 150 },\n",
    "#         { subject: 'Subject 2', data1: 75, data2: 95, maxValue: 150 },\n",
    "#         { subject: 'Subject 3', data1: 20, data2: 50, maxValue: 150 },\n",
    "#         { subject: 'Example Subject 4', data1: 65, data2: 85, maxValue: 150 },\n",
    "#         { subject: 'Food', data1: 35, data2: 45, maxValue: 150}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores():\n",
    "  subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
    "  score_results = []\n",
    "  for subjectreviews in subspecreviews:\n",
    "    if len(subjectreviews) > 0:\n",
    "      sub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
    "      if sub_sentiment_score < 0:\n",
    "        sub_sentiment_score = 0\n",
    "    else: \n",
    "      sub_sentiment_score = 75\n",
    "    score_results.append(sub_sentiment_score)\n",
    "  return score_results\n",
    "[food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score] = get_scores()\n",
    "food_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic = pd.DataFrame(df, columns = buisness_col)\n",
    "analytic.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
